#! /usr/bin/python3

import subprocess
import argparse
import numpy as np
import csv
import sys
import os
import yaml
import pprint
import time

from fabricsExperiments.generic.experiment import Experiment
from fabricsExperiments.generic.fabricPlanner import FabricPlanner
from fabricsExperiments.generic.mpcPlanner import MPCPlanner

from metrics import (
    DistanceToPointMetric,
    MinimumDistanceToPointMetric,
    TimeToReachGoalMetric,
    ClearanceMetric,
    DynamicClearanceMetric,
    SelfClearanceMetric,
    SolverTimesMetric,
    PathLengthMetric,
    SuccessMetric,
    IntegratedErrorMetric
)


def csvToRawData(fileName):
    with open(fileName) as csvfile:
        reader = csv.reader(csvfile, delimiter=",")
        return list(reader)


def listStr2FloatArray(strList):
    return np.array([float(entry) for entry in strList])


class PostProcessor(object):
    def __init__(self):
        self.initializeArgumentParser()
        self._metrices = []
        self.parseArguments()

    def initializeArgumentParser(self):
        self._parser = argparse.ArgumentParser(
            "Run post processing for motion planning experiment"
        )
        self._parser.add_argument(
            "--expFolder",
            "-exp",
            type=str,
            help="Experiment result folder",
            required=True,
        )
        self._parser.add_argument("--series", dest="series", action="store_true")
        self._parser.set_defaults(series=False)
        self._parser.add_argument("--plot", dest="plot", action="store_true")
        self._parser.set_defaults(plot=False)
        self._parser.add_argument("--verbose", dest="verbose", action="store_true")
        self._parser.set_defaults(verbose=False)
        self._parser.add_argument("--no-open", dest="openFile", action="store_false")
        self._parser.set_defaults(openFile=True)
        self._parser.add_argument(
            "--kpis", "-k",
            type=str,
            nargs="+",
            help="List of all kpis/metrics to be evaluated",
            required=True
        )

    def importData(self):
        self.convertDataPoints(csvToRawData(self._expFolder + "/res.csv"))
        self._experiment = Experiment(self._expFolder + "/exp.yaml")
        if "/fabric_" in self._expFolder or '/dynamicFabric_' in self._expFolder:
            self._planner = FabricPlanner(
                self._experiment, self._expFolder + "/planner.yaml"
            )
        elif "/mpc_" in self._expFolder:
            self._planner = MPCPlanner(
                self._experiment, self._expFolder + "/planner.yaml"
            )
        if self._experiment.robotType() == "pointMass":
            self.defineMetricesPointMass()
        elif self._experiment.robotType() == "planarArm":
            self.defineMetricesPlanarArm()
        elif self._experiment.robotType() == "panda":
            self.defineMetricesPanda()

    def parseArguments(self):
        args = self._parser.parse_args()
        self._expFolder = os.getcwd() + "/" + args.expFolder
        self._series = args.series
        self._plot = args.plot
        self._verbose = args.verbose
        self._open = args.openFile
        self._kpis = args.kpis

    def processHeader(self, header):
        headerDict = {}
        for i, entry in enumerate(header):
            headerDict[entry] = i
        return headerDict

    def convertDataPoints(self, rawdata):
        nbPoints = len(rawdata) - 1
        self._data = {}
        headerDict = self.processHeader(rawdata[0])
        for name in headerDict.keys():
            self._data[name] = np.array(
                [float(rawdata[i][headerDict[name]]) for i in range(1, nbPoints)]
            )

    def evaluateMetric(self, metricName):
        return self._metrics[metricName].computeMetric(self._data)

    def defineMetricesPointMass(self):
        self._metrics = {}
        self._metrics['time2Goal'] = TimeToReachGoalMetric(
            "time2Goal",
            ["q0", "q1", "goal_0_0", "goal_1_0", "t"],
            {"m": 2, "des_distance": 0.1},
        )
        self._metrics['integratedError'] = IntegratedErrorMetric(
            "integratedError",
            ["q0", "q1", "goal_0_0", "goal_1_0", "t"],
            {"m": 2, "des_distance": 0.1},
        )
        self._metrics['clearance'] = ClearanceMetric(
            "clearance",
            ["q0", "q1"],
            {
                "obstacles": self._experiment.obstacles(),
                "n": 1,
                "m": 2,
                "r_body": self._experiment.rBody(),
            },
        )
        self._metrics['dynamicClearance'] = DynamicClearanceMetric(
            "clearance", 
            ['q0', 'q1', 'obst_0_0', 'obst_1_0', 't'],
            {
                'r_body': self._experiment.rBody(),
                'r_obst': self._experiment.obstacles()[0].r(), 
                'm': 2,
                'n': 1
            }
        )
        self._metrics['solverTime'] = SolverTimesMetric(
            "solverTime", ["t_planning"], {"interval": self._planner.interval()}
        )
        self._metrics['pathLength'] = PathLengthMetric("pathLength", ["q0", "q1"], {})

    def defineMetricesPlanarArm(self):
        self._metrics = {}
        n = self._experiment.n()
        m = 2
        fksNames = []
        for i in range(1, n + 1):
            fksNames.append("fk" + str(i) + "_x")
            fksNames.append("fk" + str(i) + "_y")
        fkNames = ["fk" + str(n) + "_x", "fk" + str(n) + "_y"]
        self._metrics['time2Goal'] = TimeToReachGoalMetric(
            "time2Goal",
            fkNames + ['goal_0_0', 'goal_1_0', "t"],
            {"m": 2, "des_distance": 0.1},
        )
        self._metrics['integratedError'] = IntegratedErrorMetric(
            "integratedError",
            fkNames + ["goal_0_0", "goal_1_0", "t"],
            {"m": 2, "des_distance": 0.1},
        )
        self._metrics['clearance'] = ClearanceMetric(
            "clearance",
            fksNames,
            {
                "obstacles": self._experiment.obstacles(),
                "m": m,
                "n": n,
                "r_body": self._experiment.rBody(),
            },
        )
        self._metrics['dynamicClearance'] = DynamicClearanceMetric(
            "clearance", 
            fksNames + ['obst_0_0', 'obst_1_0', 't'],
            {
                'r_body': self._experiment.rBody(),
                'r_obst': self._experiment.obstacles()[0].r(), 
                'm': m,
                'n': n
            }
        )
        self._metrics['selfClearance'] = SelfClearanceMetric(
            "selfClearance",
            ["fk0_x", "fk0_y"] + fksNames,
            {
                "m": m,
                "n": n,
                "r_body": self._experiment.rBody(),
                "pairs": self._experiment.selfCollisionPairs()}
        )
        self._metrics['solverTime'] = SolverTimesMetric(
            "solverTime", ["t_planning"], {"interval": self._planner.interval()}
        )
        self._metrics['pathLength'] = PathLengthMetric("pathLength", fkNames, {})

    def defineMetricesPanda(self):
        self._metrics = {}
        n = self._experiment.n()
        m = 3
        fksNames = []
        for i in range(1, n + 1):
            fksNames.append("fk" + str(i) + "_x")
            fksNames.append("fk" + str(i) + "_y")
            fksNames.append("fk" + str(i) + "_z")
        fkNames = ["fk" + str(n) + "_x", "fk" + str(n) + "_y", "fk" + str(n) + "_z"]
        self._metrics['time2Goal'] = TimeToReachGoalMetric(
            "time2Goal",
            fkNames + ['goal_0_0', 'goal_1_0', 'goal_2_0', "t"],
            {"m": 3, "des_distance": 0.05},
        )
        self._metrics['integratedError'] = IntegratedErrorMetric(
            "integratedError",
            fkNames + ["goal_0_0", "goal_1_0", 'goal_2_0', "t"],
            {"m": 3, "des_distance": 0.1},
        )
        self._metrics['clearance'] = ClearanceMetric(
            "clearance",
            fksNames,
            {
                "obstacles": self._experiment.obstacles(),
                "m": m,
                "n": n,
                "r_body": self._experiment.rBody(),
            },
        )
        self._metrics['dynamicClearance'] = DynamicClearanceMetric(
            "clearance", 
            fksNames + ['obst_0_0', 'obst_1_0', 'obst_2_0', 't'],
            {
                'r_body': self._experiment.rBody(),
                'r_obst': self._experiment.obstacles()[0].r(), 
                'm': m,
                'n': n
            }
        )
        self._metrics['selfClearance'] = SelfClearanceMetric(
            "selfClearance",
            ["fk0_x", "fk0_y", "fk0_z"] + fksNames,
            {
                "m": m,
                "n": n,
                "r_body": self._experiment.rBody(),
                "pairs": self._experiment.selfCollisionPairs(),
            },
        )
        self._metrics['solverTime'] = SolverTimesMetric(
            "solverTime", ["t_planning"], {"interval": self._planner.interval()}
        )
        self._metrics['pathLength'] = PathLengthMetric("pathLength", fkNames, {})

    def evaluate(self):
        if self._series:
            self.seriesEvaluate(self._kpis)
        else:
            self.singleEvaluate()

    def seriesEvaluate(self, kpiNames):
        seriesFolder = self._expFolder
        listExpFolders = os.listdir(self._expFolder)
        totalExps = 0
        fullPaths = [self._expFolder + "/" + exp for exp in listExpFolders]
        kpis = {}
        for fullPath in fullPaths:
            if not os.path.isdir(fullPath):
                continue
            totalExps += 1
            self._expFolder = fullPath
            self.singleEvaluate()
            timeStamp = self.getTimeStamp()
            kpi = self.getKpis(kpiNames)
            if not self._planner.plannerType() in kpis.keys():
                kpis[self._planner.plannerType()] = {}
            kpis[self._planner.plannerType()][timeStamp] = kpi
        resultArray, feasibility, success = self.getSeriesComparison(kpis, kpiNames)
        self._expFolder = seriesFolder
        self.writeSeriesResult(kpis, resultArray, feasibility, success)
        if self._plot:
            planners = list(kpis.keys())
            self.plotSeriesResult(planners[0], planners[1], kpiNames)

    def getSeriesComparison(self, kpis, kpiNames):
        planner1Matrix = []
        planner2Matrix = []
        planner1Counter = {0: 0, -1: 0, -2: 0}
        planner2Counter = {0: 0, -1: 0, -2: 0}
        planner1Kpis = list(kpis.values())[0]
        planner2Kpis = list(kpis.values())[1]
        feasibility = []
        for timeStamp in planner1Kpis.keys():
            planner1Success =planner1Kpis[timeStamp][0]['short']
            planner2Success = planner2Kpis[timeStamp][0]['short']
            feasibility.append(
                [timeStamp, planner1Kpis[timeStamp][0]['flag'], planner2Kpis[timeStamp][0]['flag']]
            )
            planner1Counter[planner1Kpis[timeStamp][0]['flag']] += 1
            planner2Counter[planner2Kpis[timeStamp][0]['flag']] += 1
            if planner1Success and planner2Success:
                planner1Matrix.append(planner1Kpis[timeStamp][1:])
                planner2Matrix.append(planner2Kpis[timeStamp][1:])
        results = np.array(planner2Matrix) / np.array(planner1Matrix)
        resultDict = {}
        for i, kpiName in enumerate(kpiNames):
            resultDict[kpiName] = list(results[:, i])
        success = [list(planner1Counter.values()), list(planner2Counter.values())]
        return resultDict , feasibility, success

    def getTimeStamp(self):
        return self._expFolder[-15:]

    def singleEvaluate(self):
        print("Evaluating experiment %s" % self._expFolder)
        self.importData()
        self._evaluations = {}
        for kpi in self._kpis:
            self._evaluations[kpi] = self.evaluateMetric(kpi)
        if self._verbose:
            pprint.pprint(self._evaluations)
        if self._plot:
            self.plot()
        self.evaluateSuccess()
        self.writeEval2ResultFolder()

    def getEval(self):
        return self._evaluations

    def getKpis(self, kpiNames):
        success = self._evaluations["success"]
        return [success] + [self._evaluations[kpiName]['short'] for kpiName in kpiNames]

    def evaluateSuccess(self):
        clearanceKeys = ['selfClearance', 'clearance', 'dynamicClearance']
        minClearance = 10
        clearanceChecked = False
        for clearanceKey in clearanceKeys:
            if clearanceKey in self._evaluations.keys():
                minClearance = min(minClearance, self._evaluations[clearanceKey]['short'])
                clearanceChecked = True
        if not clearanceChecked:
            import warnings
            warnings.warn("No clearance metric set")
        if 'time2Goal' in self._evaluations.keys():
            reachingFlag = self._evaluations["time2Goal"]['flag']
        else:
            print("INFO: Not evaluating whether the goal was reached.")
            reachingFlag = 0
        successMetric = SuccessMetric(
            "success", [], {"minClearance": minClearance, "reachingFlag": reachingFlag},
        )
        self._evaluations["success"] = successMetric.computeMetric(self._data)

    def writeSeriesResult(self, seriesRes, resultDict, feasibility, success):
        postProcessFile = self._expFolder + "/postProcess.yaml"
        seriesCsvFile = self._expFolder + "/results.csv"
        feasibilityFile = self._expFolder + "/feasibility.csv"
        successFile = self._expFolder + "/success.csv"
        with open(postProcessFile, "w") as file:
            yaml.dump(seriesRes, file)
        with open(seriesCsvFile, "w") as file:
            csv_writer = csv.writer(file, delimiter=",")
            csv_writer.writerow(list(resultDict))
            resultList = list(resultDict.values())
            for i in range(len(resultList[0])):
                row = [resultList[j][i] for j in range(len(resultList))]
                csv_writer.writerow(row)
        with open(feasibilityFile, "w") as file:
            csv_writer = csv.writer(file, delimiter=",")
            for i in range(len(feasibility)):
                csv_writer.writerow(feasibility[i])
        with open(successFile, "w") as file:
            csv_writer = csv.writer(file, delimiter=",")
            for i in range(len(success)):
                csv_writer.writerow(success[i])

    def writeEval2ResultFolder(self):
        postProcessFile = self._expFolder + "/postProcess.yaml"
        with open(postProcessFile, "w") as file:
            yaml.dump(self._evaluations, file)

    def plot(self):
        curPath = os.path.dirname(os.path.abspath(__file__)) + "/"
        if self._experiment.robotType() == "planarArm":
            createPlotFolder = curPath + "plottingPlanarArm"
            subprocess.Popen(
                [
                    "./createPlot",
                    self._expFolder,
                    str(self._experiment.n()),
                    str(int(self._experiment.hasDynamicObstacles()))
                ],
                cwd=createPlotFolder,
                stdout=subprocess.PIPE,
            )
        elif self._experiment.robotType() == "pointMass":
            createPlotFolder = curPath + "plottingPointMass/"
            subprocess.Popen(
                ["./createPlot", self._expFolder],
                cwd=createPlotFolder,
                stdout=subprocess.PIPE,
            )
        elif self._experiment.robotType() == "panda":
            createPlotFolder = curPath + "plottingPanda/"
            subprocess.Popen(
                ["./createPlot", self._expFolder],
                cwd=createPlotFolder,
                stdout=subprocess.PIPE,
            )
        time.sleep(1)

    def plotSeriesResult(self, planner1, planner2, kpiNames):
        curPath = os.path.dirname(os.path.abspath(__file__)) + "/"
        subprocess.Popen(
            ["./createSeriesPlot", self._expFolder, planner1, planner2] + kpiNames, cwd=curPath, stdout=subprocess.PIPE
        )
        subprocess.Popen(
            ["./createSuccessPlot", self._expFolder, planner1, planner2],
            cwd=curPath,
            stdout=subprocess.PIPE,
        )

    def open(self):
        if self._open:
            subprocess.Popen(["xdg-open", self._expFolder], stdout=subprocess.PIPE)


if __name__ == "__main__":
    pp = PostProcessor()
    pp.evaluate()
    pp.open()
